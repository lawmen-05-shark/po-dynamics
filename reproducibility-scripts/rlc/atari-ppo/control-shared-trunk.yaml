project: po-dynamics-rlc
name: atari-ppo-control-shared-trunk
method: grid
metric:
  goal: maximize
  name: batch/perf/avg_return_raw
parameters:
  wandb.mode:
    value: online
  wandb.tags:
    value: [rlc, experiment, control, shared-trunk ]
  outputs_subdir:
    value: rlconf
  job_subdir:
    value: "atari-ppo/control/shared-trunk"
  env:
    value: gym-atari
  env.name:
    values: [ "ALE/Phoenix-v5", "ALE/Gravitar-v5", "ALE/NameThisGame-v5" ]
  seed:
    values: [ 25, 7, 64 ]
  optim.num_epochs:
    values: [ 4, 6, 8 ]
  optim.anneal_linearly:
    values: [ False, True ]
  models.share_features:
    value: True
command:
  - python
  - "-m"
  - "po_dynamics.solve"
  - ${args_no_hyphens}
