project: po-dynamics-rlc
name: mujoco-ppo-control-algo
method: grid
metric:
  goal: maximize
  name: batch/perf/avg_return_raw
parameters:
  wandb.mode:
    value: online
  wandb.tags:
    value: [rlc, experiment, control, algo]
  outputs_subdir:
    value: rlconf
  job_subdir:
    value: "mujoco-ppo/control/algo"
  env:
    value: gym-mujoco
  env.name:
    values: [ "Hopper-v4", "Humanoid-v4" ]
  seed:
    values: [ 25, 7, 64 ]
  optim.num_epochs:
    values: [ 10, 15, 20 ]
  optim.anneal_linearly:
    values: [ False, True ]
  models.activation:
    values: [ Tanh, ReLU ]
  algo:
    values: [ ppo-kl, ppo-early-stop ]
  collector.total_env_steps:
    value: 5_000_000
command:
  - python
  - "-m"
  - "po_dynamics.solve"
  - ${args_no_hyphens}
